{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/archimickey/miniforge3/envs/web/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# import modules\n",
    "\n",
    "from getpass import getpass\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "import wget\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import json\n",
    "import google.generativeai as genai\n",
    "from pinecone import Pinecone, PodSpec\n",
    "import langchain\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone(\n",
    "    api_key=\"60ec97ef-7862-4555-aa8c-8f8b3f7989e2\",\n",
    ")\n",
    "index_name = 'retrieval-augmentation-generation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1792,\n",
       " 'index_fullness': 0.02781,\n",
       " 'namespaces': {'': {'vector_count': 2781}},\n",
       " 'total_vector_count': 2781}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = pc.Index(index_name)\n",
    "# view index stats\n",
    "index.describe_index_stats() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.59684855 -0.74949414  0.4362398  ...  0.03004938  0.36892733\n",
      " -0.10507792]\n"
     ]
    }
   ],
   "source": [
    "embed_self.genapi = SentenceTransformer('aspire/acge_text_embedding')\n",
    "result = embed_self.genapi.encode(\"What is the meaning of life?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "tokenizer = tiktoken.get_encoding('cl100k_base')\n",
    "\n",
    "# create the length function\n",
    "def tiktoken_len(text):\n",
    "    tokens = tokenizer.encode(\n",
    "        text,\n",
    "        disallowed_special=()\n",
    "    )\n",
    "    return len(tokens)\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=512,\n",
    "    chunk_overlap=20,\n",
    "    length_function=tiktoken_len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get google API key\n",
    "genai.configure(api_key=\"AIzaSyC71miq1uuOH1BYm5PiaoqAvDKHPbp712A\")\n",
    "\n",
    "# Define self.genapi\n",
    "MODEL = \"gemini-pro\"\n",
    "genapi = genai.GenerativeModel(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chatbot:\n",
    "    def __init__(self):\n",
    "        self.pc = Pinecone(api_key=\"60ec97ef-7862-4555-aa8c-8f8b3f7989e2\")\n",
    "        self.index_name = 'retrieval-augmentation-generation'\n",
    "        self.index = pc.Index(index_name)\n",
    "        self.embed_model = SentenceTransformer('aspire/acge_text_embedding')\n",
    "        self.tokenizer = tiktoken.get_encoding('cl100k_base')\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=512,\n",
    "    chunk_overlap=20,\n",
    "    length_function=tiktoken_len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "        genai.configure(api_key=\"AIzaSyC71miq1uuOH1BYm5PiaoqAvDKHPbp712A\")\n",
    "        MODEL = \"gemini-pro\"\n",
    "        self.genapi = genai.GenerativeModel(MODEL)\n",
    "    \n",
    "    def generate_related_query(self, qeury, num_results=4):\n",
    "        prompt = textwrap.dedent(\n",
    "            f\"\"\"\n",
    "            You are a helpful assistant that can generate multiple search queries based on a given search query. \n",
    "            Please enerate multiple search queries related to: {qeury},\n",
    "            OUTPUT: ({num_results} queries):\n",
    "            \"\"\"\n",
    "        )\n",
    "        response = self.genapi.generate_content(prompt)\n",
    "        return response.text\n",
    "    \n",
    "    def generate_fake_answer(self, qeury):\n",
    "        query_prompt = textwrap.dedent(\n",
    "            f\"\"\"\n",
    "            You are a helpful assistant of 資訊工程學系 in 國立中央大學(NCU). Please write a passage to answer the qustion. Your answer should be in sentences only and with the same language as the query.\n",
    "            Question: {qeury}\n",
    "            Passage:\n",
    "        \"\"\"\n",
    "        )\n",
    "        response = self.genapi.generate_content(query_prompt)\n",
    "        return response.text.strip()\n",
    "    \n",
    "    def vector_search(self, query, top_k=100):\n",
    "        embed_query = self.embed_model.encode(query)\n",
    "        matches = index.query(vector=embed_query.tolist(), top_k=top_k)\n",
    "        return {ret[\"id\"]: ret[\"score\"] for ret in matches.matches}\n",
    "    \n",
    "    def reciprocal_rank_fusion(self, search_results, k=60):\n",
    "        fused_results = {}\n",
    "\n",
    "        for query, results in search_results.items():\n",
    "            for rank, (doc_id, score) in enumerate(results.items()):\n",
    "                if doc_id not in fused_results:\n",
    "                    fused_results[doc_id] = 0\n",
    "                fused_results[doc_id] += 1 / (rank + k)\n",
    "        \n",
    "        reranked_results = {doc_id: score for doc_id, score in sorted(fused_results.items(), key=lambda x: x[1], reverse=True)}\n",
    "        return reranked_results\n",
    "    \n",
    "    def generate_hit_results(self, results, num_results=3):\n",
    "        retrival_data = []\n",
    "        searching_ids = list(results.keys())[:num_results]\n",
    "        result = index.fetch(searching_ids)\n",
    "        for id in searching_ids:\n",
    "            retrival_data.append(result[\"vectors\"][id].metadata)\n",
    "        hit_results = []\n",
    "        for i, data in enumerate(retrival_data):\n",
    "            r = \"\"\n",
    "            r += f\"'''No.{i+1} {data['title']}: {data['source']}\\n\"\n",
    "            r += f\"No.{i+1} data: {data['text']}'''\\n\"\n",
    "            hit_results.append(r)\n",
    "        return hit_results\n",
    "    \n",
    "    def generate_output(self, query, hit_result):\n",
    "        prompt = textwrap.dedent(\"\"\"QUESTION: '{query}'\n",
    "    PASSAGE: '{relevant_passage}'\n",
    "    You are a great assistant. There are a total of several pieces of searched information here. Please extract the relevant parts of each piece of information based on the user's question and organize it into complete and understandable content and reply to the user. Please extract the information one by one with the given order. You should use the language of input to answer this question. Make sure there are no omission, and provide the source URL of all pieces of information.\n",
    "    OUTPUT: (Information extracted with all {length} pieces of information in order.)\n",
    "    \"\"\").format(query=query, relevant_passage=hit_result, length=len(hit_result))\n",
    "        return self.genapi.generate_content(prompt)\n",
    "    \n",
    "    def generate_answer(self, query):\n",
    "        fake_answers = [self.generate_fake_answer(q) for q in [query, *[self.generate_related_query(query).split(\"\\n\")]] if q]\n",
    "        # print(fake_answers)\n",
    "        gathered_results = {}\n",
    "        for q in fake_answers:\n",
    "            search_results = self.vector_search(q)\n",
    "            gathered_results[q] = search_results\n",
    "        # display(gathered_results)\n",
    "        results = self.reciprocal_rank_fusion(gathered_results)\n",
    "        hit_result = self.generate_hit_results(results)\n",
    "        # print(hit_result)\n",
    "        return self.generate_output(query, hit_result)\n",
    "    \n",
    "    def choose_action(self, query):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot = Chatbot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      " | Search:  系上的修業規定?  | \n",
      "根據您的問題，我們找到了以下資訊：\n",
      "1. **系上的修業規定?**\n",
      "[修業規定](https://www.csie.ncu.edu.tw/information/course)\n",
      "修業規定請參考註冊組網頁\n",
      "\n",
      "\n",
      "2. **系訂必修 60 學分\\n選俢45 學分**\n",
      "[課程設計](https://www.csie.ncu.edu.tw/information/course)\n",
      "專業師資\n",
      "畢業生就業流向\n",
      "入學資訊\n",
      "招生資訊\n",
      "課程設計\n",
      "最新修業辦法請參考 教務處網頁\n",
      "課程設計理念\n",
      "本系課程規劃分三部份，藉由共同必修、數學及基礎科學課程、工程專業課程等三方面的課程規劃給於學生完整的學習系統。其中共同必修由校共同必修科目以及核心通識組成：包含校共同必修國文、英文、歷史以及通識課程。\n",
      "共同必修 23 學分： 校共同必修(9學分)及通識(含核心必修、 選修)(14 學分)。\n",
      "系訂必修 60 學分\n",
      "選俢45 學分\n",
      "\n",
      "\n",
      "3. **修業規定請參考註冊組網頁**\n",
      "[課程設計](https://www.csie.ncu.edu.tw/information/course)\n",
      "修業規定\n",
      "修業規定請參考註冊組網頁\n",
      "學分學程修讀規定\n",
      "請參考課務組網頁\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "query = \"系上的修業規定?\"\n",
    "answer = chatbot.generate_answer(query)\n",
    "\n",
    "print(\"------------------------------------------------------------\")\n",
    "print(\" | Search: \", query, \" | \")\n",
    "print(\"根據您的問題，我們找到了以下資訊：\")\n",
    "print(answer.text)\n",
    "print(\"------------------------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "web",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
